{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Deep Learning : Fundamentals and Applications\n",
    "\n",
    "## Requirements\n",
    "- python 2.x or 3.x\n",
    "- numpy\n",
    "- keras\n",
    "- tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# make the code compatible with both Python 2 and 3\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step \t W \t b\n",
      "0 [-0.28137255] [ 0.92591405]\n",
      "20 [ 0.27944958] [ 0.41141459]\n",
      "40 [ 0.44437158] [ 0.32810161]\n",
      "60 [ 0.4859691] [ 0.30708793]\n",
      "80 [ 0.49646109] [ 0.30178776]\n",
      "100 [ 0.49910739] [ 0.30045092]\n",
      "120 [ 0.49977487] [ 0.30011374]\n",
      "140 [ 0.49994326] [ 0.30002868]\n",
      "160 [ 0.49998567] [ 0.30000725]\n",
      "180 [ 0.49999636] [ 0.30000186]\n",
      "200 [ 0.49999908] [ 0.30000049]\n"
     ]
    }
   ],
   "source": [
    "# Create 100 phony x, y data points in NumPy, y = x * 0.5 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.5 + 0.3\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "print(\"Step \\t W \\t b\")\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytpeng0418\\Miniconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10 samples\n",
      "Epoch 1/200\n",
      "100/100 [==============================] - 0s - loss: 0.1320 - acc: 0.0000e+00 - val_loss: 0.0998 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 0s - loss: 0.0839 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 0s - loss: 0.0529 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 0s - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 0s - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 0s - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 0s - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0065 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 0s - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 0s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 0s - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 0s - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 0s - loss: 9.4942e-04 - acc: 0.0000e+00 - val_loss: 7.2868e-04 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 0s - loss: 6.2295e-04 - acc: 0.0000e+00 - val_loss: 4.8460e-04 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 0s - loss: 4.1689e-04 - acc: 0.0000e+00 - val_loss: 3.2894e-04 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 0s - loss: 2.8529e-04 - acc: 0.0000e+00 - val_loss: 2.3202e-04 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 0s - loss: 2.0309e-04 - acc: 0.0000e+00 - val_loss: 1.6839e-04 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 0s - loss: 1.4904e-04 - acc: 0.0000e+00 - val_loss: 1.2650e-04 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 0s - loss: 1.1295e-04 - acc: 0.0000e+00 - val_loss: 9.7948e-05 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 0s - loss: 8.8645e-05 - acc: 0.0000e+00 - val_loss: 8.0449e-05 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 0s - loss: 7.3618e-05 - acc: 0.0000e+00 - val_loss: 6.7376e-05 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 0s - loss: 6.2338e-05 - acc: 0.0000e+00 - val_loss: 6.0693e-05 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 0s - loss: 5.6412e-05 - acc: 0.0000e+00 - val_loss: 5.5771e-05 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 0s - loss: 5.2050e-05 - acc: 0.0000e+00 - val_loss: 5.1937e-05 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 0s - loss: 4.8697e-05 - acc: 0.0000e+00 - val_loss: 4.8901e-05 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 0s - loss: 4.5859e-05 - acc: 0.0000e+00 - val_loss: 4.6820e-05 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 0s - loss: 4.4003e-05 - acc: 0.0000e+00 - val_loss: 4.5336e-05 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 0s - loss: 4.2576e-05 - acc: 0.0000e+00 - val_loss: 4.4033e-05 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 0s - loss: 4.1388e-05 - acc: 0.0000e+00 - val_loss: 4.2747e-05 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 0s - loss: 4.0065e-05 - acc: 0.0000e+00 - val_loss: 4.1742e-05 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 0s - loss: 3.9135e-05 - acc: 0.0000e+00 - val_loss: 4.0799e-05 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 0s - loss: 3.8301e-05 - acc: 0.0000e+00 - val_loss: 3.9873e-05 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 0s - loss: 3.7428e-05 - acc: 0.0000e+00 - val_loss: 3.8929e-05 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 0s - loss: 3.6508e-05 - acc: 0.0000e+00 - val_loss: 3.7948e-05 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 0s - loss: 3.5584e-05 - acc: 0.0000e+00 - val_loss: 3.7140e-05 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 0s - loss: 3.4784e-05 - acc: 0.0000e+00 - val_loss: 3.6342e-05 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 0s - loss: 3.4059e-05 - acc: 0.0000e+00 - val_loss: 3.5575e-05 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 0s - loss: 3.3361e-05 - acc: 0.0000e+00 - val_loss: 3.4820e-05 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 0s - loss: 3.2640e-05 - acc: 0.0000e+00 - val_loss: 3.4065e-05 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 0s - loss: 3.1899e-05 - acc: 0.0000e+00 - val_loss: 3.3299e-05 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 0s - loss: 3.1205e-05 - acc: 0.0000e+00 - val_loss: 3.2560e-05 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 0s - loss: 3.0469e-05 - acc: 0.0000e+00 - val_loss: 3.1824e-05 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 0s - loss: 2.9802e-05 - acc: 0.0000e+00 - val_loss: 3.1112e-05 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 0s - loss: 2.9131e-05 - acc: 0.0000e+00 - val_loss: 3.0402e-05 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 0s - loss: 2.8519e-05 - acc: 0.0000e+00 - val_loss: 2.9712e-05 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 0s - loss: 2.7862e-05 - acc: 0.0000e+00 - val_loss: 2.9069e-05 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 0s - loss: 2.7218e-05 - acc: 0.0000e+00 - val_loss: 2.8386e-05 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 0s - loss: 2.6558e-05 - acc: 0.0000e+00 - val_loss: 2.7728e-05 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 0s - loss: 2.6021e-05 - acc: 0.0000e+00 - val_loss: 2.7082e-05 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 0s - loss: 2.5372e-05 - acc: 0.0000e+00 - val_loss: 2.6479e-05 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 0s - loss: 2.4833e-05 - acc: 0.0000e+00 - val_loss: 2.5834e-05 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 0s - loss: 2.4227e-05 - acc: 0.0000e+00 - val_loss: 2.5263e-05 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 0s - loss: 2.3669e-05 - acc: 0.0000e+00 - val_loss: 2.4664e-05 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 0s - loss: 2.3094e-05 - acc: 0.0000e+00 - val_loss: 2.4106e-05 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 0s - loss: 2.2671e-05 - acc: 0.0000e+00 - val_loss: 2.3566e-05 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 0s - loss: 2.2082e-05 - acc: 0.0000e+00 - val_loss: 2.3031e-05 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 0s - loss: 2.1630e-05 - acc: 0.0000e+00 - val_loss: 2.2530e-05 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 0s - loss: 2.1118e-05 - acc: 0.0000e+00 - val_loss: 2.2048e-05 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 0s - loss: 2.0694e-05 - acc: 0.0000e+00 - val_loss: 2.1523e-05 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 0s - loss: 2.0169e-05 - acc: 0.0000e+00 - val_loss: 2.1015e-05 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 0s - loss: 1.9721e-05 - acc: 0.0000e+00 - val_loss: 2.0526e-05 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 0s - loss: 1.9237e-05 - acc: 0.0000e+00 - val_loss: 2.0064e-05 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 0s - loss: 1.8801e-05 - acc: 0.0000e+00 - val_loss: 1.9640e-05 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 0s - loss: 1.8404e-05 - acc: 0.0000e+00 - val_loss: 1.9200e-05 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 0s - loss: 1.8001e-05 - acc: 0.0000e+00 - val_loss: 1.8765e-05 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 0s - loss: 1.7570e-05 - acc: 0.0000e+00 - val_loss: 1.8349e-05 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 0s - loss: 1.7193e-05 - acc: 0.0000e+00 - val_loss: 1.7939e-05 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 0s - loss: 1.6808e-05 - acc: 0.0000e+00 - val_loss: 1.7542e-05 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 0s - loss: 1.6438e-05 - acc: 0.0000e+00 - val_loss: 1.7150e-05 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 0s - loss: 1.6075e-05 - acc: 0.0000e+00 - val_loss: 1.6786e-05 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 0s - loss: 1.5734e-05 - acc: 0.0000e+00 - val_loss: 1.6418e-05 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 0s - loss: 1.5368e-05 - acc: 0.0000e+00 - val_loss: 1.6068e-05 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 0s - loss: 1.5041e-05 - acc: 0.0000e+00 - val_loss: 1.5668e-05 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 0s - loss: 1.4681e-05 - acc: 0.0000e+00 - val_loss: 1.5310e-05 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 0s - loss: 1.4344e-05 - acc: 0.0000e+00 - val_loss: 1.4952e-05 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 0s - loss: 1.4035e-05 - acc: 0.0000e+00 - val_loss: 1.4608e-05 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 0s - loss: 1.3683e-05 - acc: 0.0000e+00 - val_loss: 1.4273e-05 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 0s - loss: 1.3388e-05 - acc: 0.0000e+00 - val_loss: 1.3967e-05 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 0s - loss: 1.3107e-05 - acc: 0.0000e+00 - val_loss: 1.3637e-05 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 0s - loss: 1.2786e-05 - acc: 0.0000e+00 - val_loss: 1.3343e-05 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 0s - loss: 1.2491e-05 - acc: 0.0000e+00 - val_loss: 1.3054e-05 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 0s - loss: 1.2220e-05 - acc: 0.0000e+00 - val_loss: 1.2766e-05 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 0s - loss: 1.1965e-05 - acc: 0.0000e+00 - val_loss: 1.2495e-05 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 0s - loss: 1.1700e-05 - acc: 0.0000e+00 - val_loss: 1.2212e-05 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 0s - loss: 1.1442e-05 - acc: 0.0000e+00 - val_loss: 1.1944e-05 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 0s - loss: 1.1181e-05 - acc: 0.0000e+00 - val_loss: 1.1675e-05 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 0s - loss: 1.0927e-05 - acc: 0.0000e+00 - val_loss: 1.1402e-05 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 0s - loss: 1.0676e-05 - acc: 0.0000e+00 - val_loss: 1.1157e-05 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 0s - loss: 1.0454e-05 - acc: 0.0000e+00 - val_loss: 1.0922e-05 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 0s - loss: 1.0232e-05 - acc: 0.0000e+00 - val_loss: 1.0657e-05 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 0s - loss: 9.9896e-06 - acc: 0.0000e+00 - val_loss: 1.0429e-05 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 0s - loss: 9.7708e-06 - acc: 0.0000e+00 - val_loss: 1.0195e-05 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 0s - loss: 9.5408e-06 - acc: 0.0000e+00 - val_loss: 9.9594e-06 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 0s - loss: 9.3210e-06 - acc: 0.0000e+00 - val_loss: 9.7332e-06 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 0s - loss: 9.1195e-06 - acc: 0.0000e+00 - val_loss: 9.5265e-06 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 0s - loss: 8.9202e-06 - acc: 0.0000e+00 - val_loss: 9.2995e-06 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 0s - loss: 8.7095e-06 - acc: 0.0000e+00 - val_loss: 9.0889e-06 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 0s - loss: 8.5164e-06 - acc: 0.0000e+00 - val_loss: 8.8909e-06 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 0s - loss: 8.3316e-06 - acc: 0.0000e+00 - val_loss: 8.6939e-06 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 0s - loss: 8.1379e-06 - acc: 0.0000e+00 - val_loss: 8.5005e-06 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 0s - loss: 7.9566e-06 - acc: 0.0000e+00 - val_loss: 8.3087e-06 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 0s - loss: 7.7752e-06 - acc: 0.0000e+00 - val_loss: 8.1161e-06 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 0s - loss: 7.6019e-06 - acc: 0.0000e+00 - val_loss: 7.9375e-06 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 0s - loss: 7.4402e-06 - acc: 0.0000e+00 - val_loss: 7.7608e-06 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 0s - loss: 7.2714e-06 - acc: 0.0000e+00 - val_loss: 7.5875e-06 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 0s - loss: 7.1148e-06 - acc: 0.0000e+00 - val_loss: 7.4085e-06 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 0s - loss: 6.9465e-06 - acc: 0.0000e+00 - val_loss: 7.2333e-06 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 0s - loss: 6.7792e-06 - acc: 0.0000e+00 - val_loss: 7.0752e-06 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 0s - loss: 6.6304e-06 - acc: 0.0000e+00 - val_loss: 6.9220e-06 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 0s - loss: 6.4831e-06 - acc: 0.0000e+00 - val_loss: 6.7671e-06 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 0s - loss: 6.3352e-06 - acc: 0.0000e+00 - val_loss: 6.6180e-06 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 0s - loss: 6.2060e-06 - acc: 0.0000e+00 - val_loss: 6.4757e-06 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 0s - loss: 6.0610e-06 - acc: 0.0000e+00 - val_loss: 6.3279e-06 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 0s - loss: 5.9272e-06 - acc: 0.0000e+00 - val_loss: 6.1843e-06 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 0s - loss: 5.7915e-06 - acc: 0.0000e+00 - val_loss: 6.0519e-06 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 0s - loss: 5.6690e-06 - acc: 0.0000e+00 - val_loss: 5.9177e-06 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 0s - loss: 5.5422e-06 - acc: 0.0000e+00 - val_loss: 5.7820e-06 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s - loss: 5.4179e-06 - acc: 0.0000e+00 - val_loss: 5.6541e-06 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 0s - loss: 5.2925e-06 - acc: 0.0000e+00 - val_loss: 5.5212e-06 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 0s - loss: 5.1802e-06 - acc: 0.0000e+00 - val_loss: 5.3970e-06 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 0s - loss: 5.0544e-06 - acc: 0.0000e+00 - val_loss: 5.2762e-06 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "100/100 [==============================] - 0s - loss: 4.9466e-06 - acc: 0.0000e+00 - val_loss: 5.1581e-06 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 0s - loss: 4.8332e-06 - acc: 0.0000e+00 - val_loss: 5.0420e-06 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 0s - loss: 4.7235e-06 - acc: 0.0000e+00 - val_loss: 4.9225e-06 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 0s - loss: 4.6142e-06 - acc: 0.0000e+00 - val_loss: 4.8188e-06 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 0s - loss: 4.5145e-06 - acc: 0.0000e+00 - val_loss: 4.7100e-06 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 0s - loss: 4.4135e-06 - acc: 0.0000e+00 - val_loss: 4.6060e-06 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 0s - loss: 4.3153e-06 - acc: 0.0000e+00 - val_loss: 4.5004e-06 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 0s - loss: 4.2147e-06 - acc: 0.0000e+00 - val_loss: 4.3985e-06 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 0s - loss: 4.1251e-06 - acc: 0.0000e+00 - val_loss: 4.3018e-06 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 0s - loss: 4.0324e-06 - acc: 0.0000e+00 - val_loss: 4.2071e-06 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 0s - loss: 3.9450e-06 - acc: 0.0000e+00 - val_loss: 4.1110e-06 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 0s - loss: 3.8527e-06 - acc: 0.0000e+00 - val_loss: 4.0221e-06 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 0s - loss: 3.7778e-06 - acc: 0.0000e+00 - val_loss: 3.9356e-06 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 0s - loss: 3.6847e-06 - acc: 0.0000e+00 - val_loss: 3.8439e-06 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 0s - loss: 3.6037e-06 - acc: 0.0000e+00 - val_loss: 3.7595e-06 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 0s - loss: 3.5219e-06 - acc: 0.0000e+00 - val_loss: 3.6756e-06 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 0s - loss: 3.4481e-06 - acc: 0.0000e+00 - val_loss: 3.5953e-06 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 0s - loss: 3.3666e-06 - acc: 0.0000e+00 - val_loss: 3.5124e-06 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 0s - loss: 3.2900e-06 - acc: 0.0000e+00 - val_loss: 3.4372e-06 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 0s - loss: 3.2180e-06 - acc: 0.0000e+00 - val_loss: 3.3608e-06 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 0s - loss: 3.1449e-06 - acc: 0.0000e+00 - val_loss: 3.2821e-06 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 0s - loss: 3.0741e-06 - acc: 0.0000e+00 - val_loss: 3.1993e-06 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 0s - loss: 2.9970e-06 - acc: 0.0000e+00 - val_loss: 3.1256e-06 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 0s - loss: 2.9282e-06 - acc: 0.0000e+00 - val_loss: 3.0564e-06 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 0s - loss: 2.8656e-06 - acc: 0.0000e+00 - val_loss: 2.9899e-06 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 0s - loss: 2.8051e-06 - acc: 0.0000e+00 - val_loss: 2.9229e-06 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 0s - loss: 2.7381e-06 - acc: 0.0000e+00 - val_loss: 2.8607e-06 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 0s - loss: 2.6839e-06 - acc: 0.0000e+00 - val_loss: 2.7968e-06 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 0s - loss: 2.6193e-06 - acc: 0.0000e+00 - val_loss: 2.7301e-06 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 0s - loss: 2.5599e-06 - acc: 0.0000e+00 - val_loss: 2.6690e-06 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 0s - loss: 2.5026e-06 - acc: 0.0000e+00 - val_loss: 2.6103e-06 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 0s - loss: 2.4463e-06 - acc: 0.0000e+00 - val_loss: 2.5545e-06 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 0s - loss: 2.3930e-06 - acc: 0.0000e+00 - val_loss: 2.4951e-06 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 0s - loss: 2.3355e-06 - acc: 0.0000e+00 - val_loss: 2.4381e-06 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 0s - loss: 2.2877e-06 - acc: 0.0000e+00 - val_loss: 2.3841e-06 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 0s - loss: 2.2313e-06 - acc: 0.0000e+00 - val_loss: 2.3285e-06 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 0s - loss: 2.1838e-06 - acc: 0.0000e+00 - val_loss: 2.2762e-06 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 0s - loss: 2.1319e-06 - acc: 0.0000e+00 - val_loss: 2.2272e-06 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "100/100 [==============================] - 0s - loss: 2.0851e-06 - acc: 0.0000e+00 - val_loss: 2.1803e-06 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 0s - loss: 2.0458e-06 - acc: 0.0000e+00 - val_loss: 2.1285e-06 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 0s - loss: 1.9965e-06 - acc: 0.0000e+00 - val_loss: 2.0821e-06 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 0s - loss: 1.9571e-06 - acc: 0.0000e+00 - val_loss: 2.0376e-06 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 0s - loss: 1.9103e-06 - acc: 0.0000e+00 - val_loss: 1.9936e-06 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 0s - loss: 1.8668e-06 - acc: 0.0000e+00 - val_loss: 1.9471e-06 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 0s - loss: 1.8233e-06 - acc: 0.0000e+00 - val_loss: 1.9019e-06 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 0s - loss: 1.7826e-06 - acc: 0.0000e+00 - val_loss: 1.8602e-06 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 0s - loss: 1.7442e-06 - acc: 0.0000e+00 - val_loss: 1.8191e-06 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 0s - loss: 1.7025e-06 - acc: 0.0000e+00 - val_loss: 1.7774e-06 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 0s - loss: 1.6678e-06 - acc: 0.0000e+00 - val_loss: 1.7398e-06 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 0s - loss: 1.6295e-06 - acc: 0.0000e+00 - val_loss: 1.7010e-06 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 0s - loss: 1.5928e-06 - acc: 0.0000e+00 - val_loss: 1.6639e-06 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 0s - loss: 1.5617e-06 - acc: 0.0000e+00 - val_loss: 1.6269e-06 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 0s - loss: 1.5242e-06 - acc: 0.0000e+00 - val_loss: 1.5903e-06 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 0s - loss: 1.4894e-06 - acc: 0.0000e+00 - val_loss: 1.5552e-06 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      "100/100 [==============================] - 0s - loss: 1.4566e-06 - acc: 0.0000e+00 - val_loss: 1.5199e-06 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 0s - loss: 1.4250e-06 - acc: 0.0000e+00 - val_loss: 1.4877e-06 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 0s - loss: 1.3926e-06 - acc: 0.0000e+00 - val_loss: 1.4561e-06 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      "100/100 [==============================] - 0s - loss: 1.3635e-06 - acc: 0.0000e+00 - val_loss: 1.4247e-06 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 0s - loss: 1.3358e-06 - acc: 0.0000e+00 - val_loss: 1.3935e-06 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 0s - loss: 1.3060e-06 - acc: 0.0000e+00 - val_loss: 1.3616e-06 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 0s - loss: 1.2745e-06 - acc: 0.0000e+00 - val_loss: 1.3324e-06 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 0s - loss: 1.2480e-06 - acc: 0.0000e+00 - val_loss: 1.3027e-06 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 0s - loss: 1.2193e-06 - acc: 0.0000e+00 - val_loss: 1.2715e-06 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 0s - loss: 1.1899e-06 - acc: 0.0000e+00 - val_loss: 1.2438e-06 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 0s - loss: 1.1644e-06 - acc: 0.0000e+00 - val_loss: 1.2171e-06 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 0s - loss: 1.1409e-06 - acc: 0.0000e+00 - val_loss: 1.1880e-06 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 0s - loss: 1.1128e-06 - acc: 0.0000e+00 - val_loss: 1.1620e-06 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 0s - loss: 1.0886e-06 - acc: 0.0000e+00 - val_loss: 1.1375e-06 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 0s - loss: 1.0651e-06 - acc: 0.0000e+00 - val_loss: 1.1116e-06 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 0s - loss: 1.0412e-06 - acc: 0.0000e+00 - val_loss: 1.0877e-06 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 0s - loss: 1.0193e-06 - acc: 0.0000e+00 - val_loss: 1.0620e-06 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 0s - loss: 9.9457e-07 - acc: 0.0000e+00 - val_loss: 1.0393e-06 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 0s - loss: 9.7439e-07 - acc: 0.0000e+00 - val_loss: 1.0149e-06 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 0s - loss: 9.5019e-07 - acc: 0.0000e+00 - val_loss: 9.9295e-07 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 0s - loss: 9.3029e-07 - acc: 0.0000e+00 - val_loss: 9.6966e-07 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 0s - loss: 9.0882e-07 - acc: 0.0000e+00 - val_loss: 9.4874e-07 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 0s - loss: 8.8842e-07 - acc: 0.0000e+00 - val_loss: 9.2685e-07 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 0s - loss: 8.6846e-07 - acc: 0.0000e+00 - val_loss: 9.0618e-07 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 0s - loss: 8.4891e-07 - acc: 0.0000e+00 - val_loss: 8.8643e-07 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 0s - loss: 8.3029e-07 - acc: 0.0000e+00 - val_loss: 8.6443e-07 - val_acc: 0.0000e+00\n",
      "Test score: 8.64434582581e-07\n"
     ]
    }
   ],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load required functionality from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.5 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "xt_data= np.random.rand(10).astype(np.float32)\n",
    "y_data = x_data * 0.5 + 0.3\n",
    "yt_data= xt_data * 0.5 + 0.3\n",
    "\n",
    "X_train = np.expand_dims(x_data, axis=1)\n",
    "Y_train = np.expand_dims(y_data, axis=1)\n",
    "Xt_test = np.expand_dims(xt_data, axis=1)\n",
    "Yt_test = np.expand_dims(yt_data, axis=1)\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation=None))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])            \n",
    "\n",
    "# train the model on data\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=12, # how many images to look at together\n",
    "          nb_epoch=200,       # how many epochs to run before stopping\n",
    "          verbose=1,\n",
    "          validation_data=(Xt_test, Yt_test)\n",
    "         )\n",
    "\n",
    "# test the trained model on the testing set\n",
    "score = model.evaluate(Xt_test, Yt_test, verbose=0) \n",
    "\n",
    "print('Test score:', score[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59203088]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
