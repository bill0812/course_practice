# -*- coding: utf-8 -*-
"""autoencoder_practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ANpdDklc8F9gu9MfduKv6F_h9tq2AuAa
"""

# import basic package
import keras
from PIL import Image
import numpy as np

# import mnist and fashion_mnist dataset
from keras.datasets import mnist,fashion_mnist

# load mnist data
(train_X, train_y), (test_X, test_y) = mnist.load_data()

# load fashion mnist data
(train_fashion_X, train_fashion_y), (test_fashion_X, test_fashion_y) = fashion_mnist.load_data()

# mnist train data type
train_X.dtype

# fashion mnist train data shape
train_fashion_X.dtype

# mnist train data shape
train_X.shape

# fashion mnist train data shape
train_fashion_X.shape

# view mnist image for no.1
Image.fromarray(train_X[0])

# view fashion mnist image for no.1
Image.fromarray(train_fashion_X[0])

# make mnist data close between 0 and 1
train_X = (train_X[..., None]-127.5)/128

# make fashion mnist data close between 0 and 1
train_fashion_X = (train_fashion_X[..., None]-127.5)/128

# view mnist train data shape
train_X.shape
# train_X[0]

# view fashion mnist train data shape
train_fashion_X.shape
# train_fashion_X[0]

from IPython.display import display

# define a function to show image
def showX(X, rows=1):
    assert X.shape[0] % rows == 0
    int_X = (X*128+128).clip(0,255).astype('uint8')
    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N
    int_X_reshape = int_X.reshape(rows, -1,28,28).swapaxes(1,2).reshape(28*rows,-1)
    display(Image.fromarray(int_X_reshape))
    
# 訓練資料， X 的前 20 筆
showX(train_X[:10])
print(train_y[:10])

# define number of factor that shrink in the end
NZ = 7

from keras.models import Sequential
from keras.layers import Conv2D, Activation, GlobalAveragePooling2D

# define a network : encoder to shape to NZ
netE = Sequential([
    Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='selu', input_shape=(28,28,1)),
    # selu
    Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='selu'),
    Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='selu'),
    Conv2D(filters=NZ, kernel_size=3, strides=1, padding='valid'),
    GlobalAveragePooling2D(),
    Activation('tanh'),
    Reshape([NZ,])
])

# view summary of netE info
netE.summary()

# import some basic library
from keras.layers import Conv2DTranspose, Reshape

# define a network generator to reshape factor to image
netG = Sequential([
    Reshape( (1,1,NZ), input_shape=(NZ,)),
    Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='valid', activation='relu'),
    Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='valid', activation='relu'),
    Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu'),
    Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding='same')
    
])

# view netG's summary info
netG.summary()

from keras.models import Model

# combine two network to whole autoencoder
EG_output = netG(netE.outputs)
netEG = Model(inputs=netE.inputs, outputs=[EG_output])

# view whole network's info
netEG.summary()

import numpy as np

# random new a tensor
showX(netG.predict(np.random.normal( size=(10, NZ))))

# network to comput loss : mse ; optimizer : adam
netEG.compile(loss='mse', optimizer='adam')

# train network
netEG.fit(train_fashion_X, train_fashion_X, epochs=10)

# show result
showX(netG.predict(np.random.normal(size=(100, NZ))), 10)

# show result
showX(netEG.predict(train_X[:100]), 10)

# codes = netE.predict(train_X[:1000])
# train_fashion_y
codes = netE.predict(train_fashion_X[train_fashion_y==7])

codes.mean(axis=0)

codes

codes.std(axis=0)

z = np.random.normal(codes.mean(axis=0), scale=codes.std(axis=0), size=(100,NZ))
showX(netG.predict(z), 10)

